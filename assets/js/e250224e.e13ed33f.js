"use strict";(self.webpackChunknanocosomos_documentation=self.webpackChunknanocosomos_documentation||[]).push([[4744],{28453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>o});var a=r(96540);const t={},s=a.createContext(t);function i(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),a.createElement(s.Provider,{value:n},e.children)}},44608:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"webrtc/nanostream_webrtc_input_sources","title":"Input sources","description":"The Webcaster Client API offers versatile input options to cater to a wide range of broadcasting needs. This section of the documentation will guide you through setting up various input sources.","source":"@site/docs/webrtc/nanostream_webrtc_input_sources.md","sourceDirName":"webrtc","slug":"/webrtc/nanostream_webrtc_input_sources","permalink":"/docs/webrtc/nanostream_webrtc_input_sources","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1752847376000,"frontMatter":{"id":"nanostream_webrtc_input_sources","title":"Input sources","sidebar_label":"Input sources"},"sidebar":"nanoStream Webcaster","previous":{"title":"Support","permalink":"/docs/webrtc/nanostream_webrtc_support"},"next":{"title":"Multiple Webcasts","permalink":"/docs/webrtc/nanostream_webrtc_multiple_webcasts"}}');var t=r(74848),s=r(28453);const i={id:"nanostream_webrtc_input_sources",title:"Input sources",sidebar_label:"Input sources"},o=void 0,c={},l=[{value:"Resources",id:"resources",level:2},{value:"Supported Browsers",id:"supported-browsers",level:2},{value:"Create an input via the Webcaster",id:"create-an-input-via-the-webcaster",level:2},{value:"Manual Setup of Camera and Microphone",id:"manual-setup-of-camera-and-microphone",level:2},{value:"Setup of Screen Sharing",id:"setup-of-screen-sharing",level:2},{value:"Capture from HTML canvas",id:"capture-from-html-canvas",level:2},{value:"General workflow:",id:"general-workflow",level:3},{value:"Restrictions",id:"restrictions",level:3},{value:"Canvas streaming sample",id:"canvas-streaming-sample",level:3}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"The Webcaster Client API offers versatile input options to cater to a wide range of broadcasting needs. This section of the documentation will guide you through setting up various input sources."}),"\n",(0,t.jsx)(n.p,{children:"Sources can either be physical media devices, screen shares or virtual sources that you can create with Javascript."}),"\n",(0,t.jsxs)(n.p,{children:["The interface for creating video and audio input for the Webcaster is the ",(0,t.jsx)(n.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices",children:"MediaDevices"})," interface."]}),"\n",(0,t.jsx)(n.p,{children:"We enable two workflows for the creation of input sources:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["you can create an input source by ",(0,t.jsx)(n.a,{href:"#create-an-input-via-the-webcaster",children:"configuring the Webcaster"})]}),"\n",(0,t.jsxs)(n.li,{children:["or you can manually create different inputs, for example:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#manual-setup-of-camera-and-microphone",children:"camera & microphone"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#setup-of-screen-sharing",children:"screen share"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#capture-from-html-canvas",children:"capture from HTML canvas"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,t.jsx)(n.p,{children:"Please find additional documentation for different topics below:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Access ",(0,t.jsx)(n.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia",children:"audio and video devices"})]}),"\n",(0,t.jsxs)(n.li,{children:["Capture a ",(0,t.jsx)(n.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getDisplayMedia",children:"screen share or an application window"})]}),"\n",(0,t.jsxs)(n.li,{children:["Creating a ",(0,t.jsx)(n.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/captureStream",children:"MediaStream from a HTML canvas"})]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"supported-browsers",children:"Supported Browsers"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Physical Devices"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Cameras and Microphones can be used with all major browsers on desktop and mobile devices.\nHere is a list of supported browsers:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Google Chrome"}),"\n",(0,t.jsx)(n.li,{children:"Mozilla Firefox"}),"\n",(0,t.jsx)(n.li,{children:"Microsoft Edge Version 79 and later (Chromium-based version)"}),"\n",(0,t.jsx)(n.li,{children:"Safari"}),"\n",(0,t.jsx)(n.li,{children:"Opera"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"| Note: Always ensure that you're using up-to-date versions of browsers for optimal performance and security."}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"Screen Sharing"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Screen Sharing is supported on Desktop browsers only."}),"\n",(0,t.jsx)(n.h2,{id:"create-an-input-via-the-webcaster",children:"Create an input via the Webcaster"}),"\n",(0,t.jsxs)(n.p,{children:["The Webcaster can take over the creation of input sources for you.\nIn that case you will simply provide a configuration in the ",(0,t.jsx)(n.code,{children:"mediaStreamCfg"})," property:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"const webcaster = new window.WebcasterApiV6.Webcaster({\n    inputCfg: {\n        mediaStreamCfg: {\n            maxFramerate: 30,\n            resolution: [1280, 720],\n            audioConstraints: {\n                autoGainControl: true,\n                channelCount: 2,\n                echoCancellation: true,\n                noiseSuppression: true\n            },\n        }\n    },\n    ingestUrl: 'rtmp://bintu-stream.nanocosmos.de:1935/live',\n    serverUrl: 'https://bintu-webrtc.nanocosmos.de/p/webrtc',\n    streamName: '<STREAM-NAME-1>'\n});\n\nawait webcaster.setup()\nawait webcaster.startBroadcast()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"manual-setup-of-camera-and-microphone",children:"Manual Setup of Camera and Microphone"}),"\n",(0,t.jsxs)(n.p,{children:["To access and preview the user's camera, you can use the ",(0,t.jsx)(n.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia",children:"getUserMedia"})," method. Here's a snippet:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n\nconst webcaster = new window.WebcasterApiV6.Webcaster({\n    inputCfg: {\n        mediaStream: stream,\n    },\n    ingestUrl: 'rtmp://bintu-stream.nanocosmos.de:1935/live',\n    serverUrl: 'https://bintu-webrtc.nanocosmos.de/p/webrtc',\n    streamName: '<STREAM-NAME-1>'\n});\n\nawait webcaster.setup();\nawait webcaster.startBroadcast();\n"})}),"\n",(0,t.jsx)(n.h2,{id:"setup-of-screen-sharing",children:"Setup of Screen Sharing"}),"\n",(0,t.jsxs)(n.p,{children:["To capture a screen share, you can use the ",(0,t.jsx)(n.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getDisplayMedia",children:"getDisplayMedia"})," method. Here's a snippet:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"// First create two MediaStreams and access the regarding MediaStreamTracks\nconst audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });\nconst videoStream = await navigator.mediaDevices.getDisplayMedia({ video: true });\nconst audioTrack = audioStream.getAudioTracks()[0];\nconst videoTrack = videoStream.getVideoTracks()[0];\n// Then construct a new MediaStream from a MediaStreamTrack for video (screen share)\n// and a MediaStreamTrack for audio (microphone).\nconst stream = new MediaStream([audioTrack, videoTrack]);\n\nconst webcaster = new window.WebcasterApiV6.Webcaster({\n    inputCfg: {\n        mediaStream: stream,\n    },\n    ingestUrl: 'rtmp://bintu-stream.nanocosmos.de:1935/live',\n    serverUrl: 'https://bintu-webrtc.nanocosmos.de/p/webrtc',\n    streamName: '<STREAM-NAME-1>'\n});\n\nawait webcaster.setup();\nawait webcaster.startBroadcast();\n"})}),"\n",(0,t.jsx)(n.h2,{id:"capture-from-html-canvas",children:"Capture from HTML canvas"}),"\n",(0,t.jsx)(n.h3,{id:"general-workflow",children:"General workflow:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Acquire different video/image and/or audio sources"}),"\n",(0,t.jsxs)(n.li,{children:["Mix the sources together into one MediaStream","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Video"}),": in a canvas, write your render loop where you mix the sources together via HTML canvas drawing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Audio"}),": optionally add an audio track to the mixed stream"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Pass the resulting stream to the webcaster API"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"restrictions",children:"Restrictions"}),"\n",(0,t.jsx)(n.p,{children:"When using canvas based streams, application developers are responsible for the rendering.\nPlease take note of the following:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Maintaining the provided framerate"})," is critical for end to end latency of the webcast."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tab throttling"}),". When the current tab gets out of focus, most browsers will enable tab throttling. Timers, like ",(0,t.jsx)(n.code,{children:"setInterval"}),", will be updated less frequently. You should check wether the tab left focus, and warn your users accordingly. E.g. with the DOM ",(0,t.jsx)(n.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/Document/visibilitychange_event",children:"visibilitychange event"})]}),"\n",(0,t.jsxs)(n.li,{children:["Under certain circumstances the browsers encoder will ",(0,t.jsx)(n.strong,{children:"adapt the video resolution"}),", for example when ",(0,t.jsx)(n.strong,{children:"CPU overusage"})," is being detected."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"canvas-streaming-sample",children:"Canvas streaming sample"}),"\n",(0,t.jsx)(n.p,{children:"The following snippet demonstrates how to capture a HTML canvas and pass it to the Webcaster."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"// Rendering properties\nconst canvasWidth = 1280;\nconst canvasHeight = 720;\nconst framerate = 30;\n\n// Access your HTML canvas (<canvas id=\"my-canvas\"/> element)\nconst canvas = document.getElementById('my-canvas');\nconst context = canvas.getContext('2d');\n\n// Create a MediaStream from the canvas\nconst canvasStream = canvas.captureStream(framerate);\n\n// Optionally, add a AudioStreamTrack to our canvas stream\nconst myAudioStream = await navigator.mediaDevices.getUserMedia({ audio: true });\nconst myAudioTrack = myAudioStream.getAudioTracks()[0];\ncanvasStream.addTrack(myAudioTrack);\n\n// Simple render loop. The function calls itself 30 (framerate) times per second.\n// As an example, we simply draw the string \"Hello World\".\nfunction renderLoop() {\n    context.font = '50px serif';\n    context.fillText('Hello world', 50, 90);\n    setTimeout(loop, 1000 / framerate); // drawing at 30fps\n};\n\n// Start the render loop\nrenderLoop();\n\n// Setup the Webcaster with our manually created stream\nconst webcaster = new window.WebcasterApiV6.Webcaster({\n    inputCfg: {\n        mediaStream: canvasStream\n    },\n    ingestUrl: 'rtmp://bintu-stream.nanocosmos.de:1935/live',\n    serverUrl: 'https://bintu-webrtc.nanocosmos.de/p/webrtc',\n    streamName: '<STREAM-NAME-1>'\n});\n\nawait webcaster.setup();\nawait webcaster.startBroadcast();\n"})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);