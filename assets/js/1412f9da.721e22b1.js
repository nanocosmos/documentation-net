"use strict";(self.webpackChunknanocosomos_documentation=self.webpackChunknanocosomos_documentation||[]).push([[2083],{28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>c});var s=t(96540);const r={},i=s.createContext(r);function a(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(i.Provider,{value:n},e.children)}},32404:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"webrtc-v5/nanostream_webrtc_multiple_webcasts","title":"Multiple Webcasts","description":"Multiple Webcasts can be started from a single browser tab.","source":"@site/docs/webrtc-v5/nanostream_webrtc_multiple_webcasts.md","sourceDirName":"webrtc-v5","slug":"/webrtc-v5/nanostream_webrtc_multiple_webcasts","permalink":"/docs/webrtc-v5/nanostream_webrtc_multiple_webcasts","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1751618628000,"frontMatter":{"id":"nanostream_webrtc_multiple_webcasts","title":"Multiple Webcasts","sidebar_label":"Multiple Webcasts"},"sidebar":"nanoStream Webcaster V5","previous":{"title":"Screen Sharing","permalink":"/docs/webrtc-v5/nanostream_webrtc_screen_sharing"},"next":{"title":"Quality Settings","permalink":"/docs/webrtc-v5/nanostream_webrtc_quality"}}');var r=t(74848),i=t(28453);const a={id:"nanostream_webrtc_multiple_webcasts",title:"Multiple Webcasts",sidebar_label:"Multiple Webcasts"},c=void 0,o={},l=[{value:"Setup Multiple Webcasts",id:"setup-multiple-webcasts",level:2},{value:"Example: Camera &amp; Screen Share",id:"example-camera--screen-share",level:2},{value:"1. Create API instances",id:"1-create-api-instances",level:3},{value:"2. Starting the previews",id:"2-starting-the-previews",level:3},{value:"3. Start both workflows",id:"3-start-both-workflows",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["Multiple Webcasts can be started from a single browser tab. ",(0,r.jsx)("br",{}),"\nUse cases can be:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"broadcast multiple camera (and/or microphone) streams at once"}),"\n",(0,r.jsx)(n.li,{children:"broadcast a camera and a screen share stream"}),"\n",(0,r.jsx)(n.li,{children:"broadcast multiple audio streams"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"setup-multiple-webcasts",children:"Setup Multiple Webcasts"}),"\n",(0,r.jsx)(n.p,{children:"In order to set up multiple Webcasts you will have to create multiple instances of\nthe Webcaster API in your code. Depending on what sources you want to use for streaming,\nyou will set up those instances differently."}),"\n",(0,r.jsx)(n.h2,{id:"example-camera--screen-share",children:"Example: Camera & Screen Share"}),"\n",(0,r.jsx)(n.admonition,{title:"What we will do in this example",type:"tip",children:(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"create two instances of the API"}),"\n",(0,r.jsx)(n.li,{children:"register required event handlers"}),"\n",(0,r.jsx)(n.li,{children:"start two previews, one for camera, one for screen share"}),"\n",(0,r.jsx)(n.li,{children:"start each Webcast, once the regarding preview has succeeded"}),"\n"]})}),"\n",(0,r.jsx)(n.h3,{id:"1-create-api-instances",children:"1. Create API instances"}),"\n",(0,r.jsx)(n.p,{children:"Create two instances of the API, one for camera, one for screen share."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:"// we will broadcast a camera with the first instance\nvar camUser = new window.nanowebrtc.user();\n\n// we will broadcast a screen share with the second instance\nvar screenUser = new window.nanowebrtc.user();\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-starting-the-previews",children:"2. Starting the previews"}),"\n",(0,r.jsxs)(n.p,{children:["We have to start the previews after the device lists have been emitted.\nTherefore, we start the previews within ",(0,r.jsx)(n.a,{href:"./nanostream_webrtc_api#receiveddevicelist",children:"ReceivedDeviceList"})," event listeners for both API instances.\nRequesting devices will be done in the next step."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:"camUser.on('ReceivedDeviceList', function(event) {\n  // we received the device list, now we start a preview of the first camera in the list\n  var cameraConfig = {\n    source: 'camera',  \n    device: 0,\n    width: 1280,\n    height: 720,\n    framerate: 30\n  };\n\n  var audioDeviceConfig = {\n    device: 0 // choose first audio device found\n  };\n  \n  // preview camera in <video id=\"video-local-camera\"> tag\n  var videoElementCamera = 'video-local-camera';\n\n  camUser.startPreview({\n    videoDeviceConfig: cameraConfig,\n    audioDeviceConfig: audioDeviceConfig,\n    elementId: videoElementCamera\n  });\n});\n\nscreenUser.on('ReceivedDeviceList', function(event) {\n  // we received the device list, now we start a preview of the screen\n  var screenConfig = {\n    source: 'screen',   \n    width: 1920,\n    height: 1080,\n    framerate: 5\n  };\n\n  var audioDeviceConfig = {\n    device: 0 // choose first audio device found\n  };\n\n  // preview screen share in <video id=\"video-local-screen\"> tag\n  var videoElementScreen = 'video-local-screen';\n\n  screenUser.startPreview({\n    videoDeviceConfig: screenConfig,\n    audioDeviceConfig: audioDeviceConfig,\n    elementId: videoElementScreen\n  });\n});\n\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-start-both-workflows",children:"3. Start both workflows"}),"\n",(0,r.jsx)(n.admonition,{title:"We will now",type:"tip",children:(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"sign in to the server"}),"\n",(0,r.jsx)(n.li,{children:"request the device lists for both instances"}),"\n",(0,r.jsx)(n.li,{children:"start the webcasts once we have a preview (prepared in last step)"}),"\n"]})}),"\n",(0,r.jsxs)(n.p,{children:["After we signed in successfully, we can call ",(0,r.jsx)(n.a,{href:"./nanostream_webrtc_api#rtcusergetdevices",children:"getDevices()"}),",\nthis will emit the ",(0,r.jsx)(n.a,{href:"./nanostream_webrtc_api#receiveddevicelist",children:"ReceivedDeviceList"})," event when succeeding.\nIn this example we simply start the broadcasts immediately once the ",(0,r.jsx)(n.a,{href:"./nanostream_webrtc_api#startpreviewsuccess",children:"StartPreviewSuccess()"})," events have been fired."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:"camUser.on('SignInSuccess', function(event) {\n  camUser.getDevices(); // will fire 'ReceivedDeviceList' for the camUser\n});\n\nscreenUser.on('SignInSuccess', function(event) {\n  screenUser.getDevices(); // will fire 'ReceivedDeviceList' for the screenUser\n});\n\ncamUser.on('StartPreviewSuccess', function(event) {\n  camUser.startBroadcast({\n      transcodingTargets: {\n        output: streamUrl1,\n        streamname: streamName1,\n      }\n    }\n});\n\nscreenUser.on('StartPreviewSuccess', function(event) {\n  screenUser.startBroadcast({\n      transcodingTargets: {\n        output: streamUrl2,\n        streamname: streamName2,\n      }\n    }\n});\n\nvar signInConfig = {\n   server: config.webrtc.server, // do not change the default\n   bintuApiKey: bintuApiKey // your api key\n};\n\n// on success, both\ncamUser.signIn(signInConfig);\nscreenUser.signIn(signInConfig);\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);